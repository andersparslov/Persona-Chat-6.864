{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5HTOy4Tm3EX"
      },
      "source": [
        "#Seq2Seq Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne4u93BKnfSK"
      },
      "source": [
        "#Original GPMN\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z9M8PhA8HnN"
      },
      "source": [
        "##     Background\n",
        "Chit-chat models are often criticized for not having consistent personas and unengaging speech. A study by Zhang et al (https://arxiv.org/pdf/1801.07243.pdf) sought to rectify this issue by taking chit-chat models and (i) conditioning them on persona profile information (allowing models to display a consistent given persona), and (ii) to collect and condition on information gathered about the agent they're talking to (allowing for more engaging, tailored dialogue). Several different architectures were explored, including generative models such as the profile-agnostic Seq2Seq and the profile-conditioned Generative Profile Memory Network (GPMN). \n",
        "\n",
        "Our study (Alex Berg, Anders Parslov, Anjalie Kini) will replicate Zhang et al's study on Seq2Seq and GPMNs, and extend this work by modifying these models and introducing transformer models. This notebook contains examples on how to run Seq2Seq models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CVHJeFszzmU"
      },
      "source": [
        "##Coding Notes\n",
        "All files used and run in the unit below are from the original ParlAI implementation (parlai-master, or parlai-master-OLD in the shared repo). Note that the current ParlAI repo has deprecated and/or removed almost every file associated with the GPMN, so assembling the files required to run the GPMN took a significant amount of sleuthing and modifications to updated code (to undo deprecation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1rP93S6nn0j",
        "outputId": "8b767855-88ce-4339-e2a9-427459c944d8"
      },
      "source": [
        "#Prerequisites\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4_6R0njnzUI"
      },
      "source": [
        "%cd \"gdrive/My Drive/ParlAI-master\"\n",
        "! python setup.py develop\n",
        "! pip install torch tensorboardX stop-words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th1tn189pfzo"
      },
      "source": [
        "#Table of Contents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqJFwf5PfQyx"
      },
      "source": [
        "Just a little example of how to run Seq2Seq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD_jrFCOjPLG"
      },
      "source": [
        "#Replication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZdJUePQRJwC"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import signal\n",
        "import json\n",
        "\n",
        "from parlai.core.agents import create_agent, create_agent_from_shared, get_agent_module\n",
        "from parlai.core.worlds import create_task\n",
        "from parlai.core.params import ParlaiParser\n",
        "from parlai.core.utils import Timer, round_sigfigs, warn_once\n",
        "from parlai.core.logs import TensorboardLogger\n",
        "from parlai.scripts.build_dict import build_dict, setup_args as setup_dict_args\n",
        "from parlai.core.distributed_utils import (\n",
        "    sync_object, is_primary_worker, all_gather_list, is_distributed, num_workers\n",
        ")\n",
        "from parlai.scripts.build_pytorch_data import get_pyt_dict_file\n",
        "from parlai.scripts.train_model import *"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_9JO19uUfYK"
      },
      "source": [
        "#Option 1: Most Basic Seq2Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ183qIIZZPg"
      },
      "source": [
        "This is only an example Seq2Seq (encoder-decoder model); it is not the one they actually use. However, it does seem more easy to manipulate than the real one. See below (option 2) for the real one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLxd5D17RhNw"
      },
      "source": [
        "#task='parlai.agents.local_human.local_human:LocalHumanAgent'\n",
        "#model='projects.personachat.persona_seq2seq:PersonachatSeqseqAgentBasic'\n",
        "\n",
        "task = \"personachat\"\n",
        "model = \"seq2seq\"\n",
        "batch_size = 36\n",
        "lr = 1e-2\n",
        "hidden_size = 128\n",
        "args = f\"\"\"-m parlai.scripts.train_model -m {model} \n",
        "           -t {task} \n",
        "           -mf '/tmp/model' \n",
        "           -bs {batch_size} \n",
        "           -lr {lr} \n",
        "           -hs {hidden_size}\"\"\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYRyN5rlR3nl"
      },
      "source": [
        "opt = setup_args().parse_args(args.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKw4RxDtSAmm"
      },
      "source": [
        "trainer = TrainLoop(opt) #This just defines a training object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iqe6zuIZpVj"
      },
      "source": [
        "trainer.train() #This actually trains it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mqlbr74UlUM"
      },
      "source": [
        "#Option 2: Dedicated Seq2Seq (From original paper) -- with and without Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NWu2H8tVGYx"
      },
      "source": [
        "Check out persona_seq2seq.py in parlai-master-old -> projects -> persona_seq2seq. This is the actual version the paper uses, afaik. (The other seq2seq is merely an example of an encoder-decoder model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSYVpvestHP3"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import signal\n",
        "import json\n",
        "\n",
        "from parlai.core.agents import create_agent, create_agent_from_shared, get_agent_module\n",
        "from parlai.core.worlds import create_task\n",
        "from parlai.core.params import ParlaiParser\n",
        "from parlai.core.utils import Timer, round_sigfigs, warn_once\n",
        "from parlai.core.logs import TensorboardLogger\n",
        "from parlai.scripts.build_dict import build_dict, setup_args as setup_dict_args\n",
        "from parlai.core.distributed_utils import (sync_object, is_primary_worker, all_gather_list, is_distributed, num_workers)\n",
        "from parlai.scripts.build_pytorch_data import get_pyt_dict_file\n",
        "from parlai.scripts.train_model import *\n",
        "from projects.personachat.persona_seq2seq import PersonachatSeqseqAgentSplit #NOTE! This is the important difference between the above OPTION 1 and OPTION 2"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyK_fxnBVXC8"
      },
      "source": [
        "task = \"personachat:self\"\n",
        "model = \"projects.personachat.persona_seq2seq:PersonachatSeqseqAgentBasic\"   #NOTE! This is the important difference between the above OPTION 1 and OPTION 2\n",
        "#I have no idea what params are good for this mode; ripped this from a pre-trained model\n",
        "lr = 1e-3\n",
        "hidden_size = 1024\n",
        "dr = 0.2\n",
        "args = f\"\"\"-m {model} \n",
        "           -t {task} \n",
        "           -mf '/tmp/model' \n",
        "           -bs {batch_size} \n",
        "           -lr {lr} \n",
        "           -dr {dr}\n",
        "           -hs {hidden_size}\"\"\""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry5E7ddqWC9_"
      },
      "source": [
        "opt = setup_args().parse_args(args.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YES_gA77WMtr"
      },
      "source": [
        "trainer = TrainLoop(opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7K197AvZyqR"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0ubDz24Wq8f"
      },
      "source": [
        "#Additional: download a pretrained model and run an interactive version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJDSEgCOWxXt"
      },
      "source": [
        "from parlai.core.build_data import download_models\n",
        "from parlai.core.params import ParlaiParser\n",
        "from parlai.scripts.interactive import interactive\n",
        "from projects.personachat.persona_seq2seq import PersonachatSeqseqAgentBasic"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp3YxdXMYSfl"
      },
      "source": [
        "%cd parlai-master #probably remove this line; just make sure you're running this from the parlai-master directory\n",
        "! seq2seq_withprofile_interactive.py #put this file (currently in the projects->personachat->scripts directory) in the parlai-master directory"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}